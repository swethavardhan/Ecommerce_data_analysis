{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_df = pd.read_csv('ecommerce_data/fact_table.csv', encoding='ISO-8859-1')\n",
    "customer_df = pd.read_csv('ecommerce_data/customer_dim.csv', encoding='ISO-8859-1')\n",
    "item_df = pd.read_csv('ecommerce_data/item_dim.csv', encoding='ISO-8859-1')\n",
    "store_df = pd.read_csv('ecommerce_data/store_dim.csv', encoding='ISO-8859-1')\n",
    "time_df = pd.read_csv('ecommerce_data/time_dim.csv', encoding='ISO-8859-1')\n",
    "transaction_df = pd.read_csv('ecommerce_data/Trans_dim.csv', encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in fact_df:\n",
      "payment_key         0\n",
      "coustomer_key       0\n",
      "time_key            0\n",
      "item_key            0\n",
      "store_key           0\n",
      "quantity            0\n",
      "unit             3723\n",
      "unit_price          0\n",
      "total_price         0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Missing values in customer_df:\n",
      "coustomer_key     0\n",
      "name             27\n",
      "contact_no        0\n",
      "nid               0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Missing values in item_df:\n",
      "item_key       0\n",
      "item_name      0\n",
      "desc           0\n",
      "unit_price     0\n",
      "man_country    0\n",
      "supplier       0\n",
      "unit           1\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Missing values in store_df:\n",
      "store_key    0\n",
      "division     0\n",
      "district     0\n",
      "upazila      0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Missing values in time_df:\n",
      "time_key    0\n",
      "date        0\n",
      "hour        0\n",
      "day         0\n",
      "week        0\n",
      "month       0\n",
      "quarter     0\n",
      "year        0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Missing values in transaction_df:\n",
      "payment_key    0\n",
      "trans_type     0\n",
      "bank_name      1\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking for null values\n",
    "dfs = [fact_df, customer_df, item_df, store_df, time_df, transaction_df]\n",
    "\n",
    "for df_name, df in zip(['fact_df', 'customer_df', 'item_df', 'store_df', 'time_df', 'transaction_df'], dfs):\n",
    "    print(f'Missing values in {df_name}:')\n",
    "    print(df.isna().sum())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store_df, time_df doesn't have any null values\n",
    "#transaction_df, customer_df have null vales but are very small in number(dropping them doesn't affect the data)\n",
    "transaction_df.dropna(inplace=True)\n",
    "customer_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#got to know that item_df missing values is 'bags' so filling it\n",
    "item_df.fillna('bags', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       payment_key coustomer_key time_key item_key store_key  quantity unit  \\\n",
      "413           P030       C001653  T053668   I00158    S00327         1  NaN   \n",
      "478           P013       C008861  T036513   I00158    S00280         9  NaN   \n",
      "1500          P007       C008864  T052262   I00158    S00308         7  NaN   \n",
      "2033          P037       C002870  T050819   I00158    S00506         7  NaN   \n",
      "2053          P020       C003666  T094595   I00158     S0077        11  NaN   \n",
      "...            ...           ...      ...      ...       ...       ...  ...   \n",
      "998455        P016       C007003   T04678   I00158    S00522         1  NaN   \n",
      "998754        P039       C004215  T022792   I00158     S0092         9  NaN   \n",
      "998757        P027       C000309   T07076   I00158    S00550         9  NaN   \n",
      "999136        P033       C008559  T070336   I00158    S00553        11  NaN   \n",
      "999660        P019       C002022   T04150   I00158    S00347         7  NaN   \n",
      "\n",
      "        unit_price  total_price  \n",
      "413           17.0         17.0  \n",
      "478           17.0        153.0  \n",
      "1500          17.0        119.0  \n",
      "2033          17.0        119.0  \n",
      "2053          17.0        187.0  \n",
      "...            ...          ...  \n",
      "998455        17.0         17.0  \n",
      "998754        17.0        153.0  \n",
      "998757        17.0        153.0  \n",
      "999136        17.0        187.0  \n",
      "999660        17.0        119.0  \n",
      "\n",
      "[3723 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#fact_table has null values in one specific column 'unit' which are very large in number\n",
    "missing_unit_rows = fact_df[fact_df['unit'].isna()]\n",
    "print(missing_unit_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seems like the item key of all the missing values is same\n",
    "#after checking item_df, got to know that the unit is 'bags'\n",
    "#so lets replace nan with 'bags'\n",
    "fact_df.fillna('bags', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in fact_df:\n",
      "payment_key      0\n",
      "coustomer_key    0\n",
      "time_key         0\n",
      "item_key         0\n",
      "store_key        0\n",
      "quantity         0\n",
      "unit             0\n",
      "unit_price       0\n",
      "total_price      0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Missing values in customer_df:\n",
      "coustomer_key    0\n",
      "name             0\n",
      "contact_no       0\n",
      "nid              0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Missing values in item_df:\n",
      "item_key       0\n",
      "item_name      0\n",
      "desc           0\n",
      "unit_price     0\n",
      "man_country    0\n",
      "supplier       0\n",
      "unit           0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Missing values in store_df:\n",
      "store_key    0\n",
      "division     0\n",
      "district     0\n",
      "upazila      0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Missing values in time_df:\n",
      "time_key    0\n",
      "date        0\n",
      "hour        0\n",
      "day         0\n",
      "week        0\n",
      "month       0\n",
      "quarter     0\n",
      "year        0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Missing values in transaction_df:\n",
      "payment_key    0\n",
      "trans_type     0\n",
      "bank_name      0\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking now for null values\n",
    "dfs = [fact_df, customer_df, item_df, store_df, time_df, transaction_df]\n",
    "\n",
    "for df_name, df in zip(['fact_df', 'customer_df', 'item_df', 'store_df', 'time_df', 'transaction_df'], dfs):\n",
    "    print(f'Missing values in {df_name}:')\n",
    "    print(df.isna().sum())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#done with handling null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#checking for duplicate rows\n",
    "print(customer_df.duplicated().sum())\n",
    "print(fact_df.duplicated().sum())\n",
    "print(item_df.duplicated().sum())\n",
    "print(store_df.duplicated().sum())\n",
    "print(transaction_df.duplicated().sum())\n",
    "print(time_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data types of fact_df:\n",
      "payment_key       object\n",
      "coustomer_key     object\n",
      "time_key          object\n",
      "item_key          object\n",
      "store_key         object\n",
      "quantity           int64\n",
      "unit              object\n",
      "unit_price       float64\n",
      "total_price      float64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "data types of customer_df:\n",
      "coustomer_key    object\n",
      "name             object\n",
      "contact_no        int64\n",
      "nid               int64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "data types of item_df:\n",
      "item_key        object\n",
      "item_name       object\n",
      "desc            object\n",
      "unit_price     float64\n",
      "man_country     object\n",
      "supplier        object\n",
      "unit            object\n",
      "dtype: object\n",
      "\n",
      "\n",
      "data types of store_df:\n",
      "store_key    object\n",
      "division     object\n",
      "district     object\n",
      "upazila      object\n",
      "dtype: object\n",
      "\n",
      "\n",
      "data types of time_df:\n",
      "time_key    object\n",
      "date        object\n",
      "hour         int64\n",
      "day          int64\n",
      "week        object\n",
      "month        int64\n",
      "quarter     object\n",
      "year         int64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "data types of transaction_df:\n",
      "payment_key    object\n",
      "trans_type     object\n",
      "bank_name      object\n",
      "dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking now for null values\n",
    "dfs = [fact_df, customer_df, item_df, store_df, time_df, transaction_df]\n",
    "\n",
    "for df_name, df in zip(['fact_df', 'customer_df', 'item_df', 'store_df', 'time_df', 'transaction_df'], dfs):\n",
    "    print(f'data types of {df_name}:')\n",
    "    print(df.dtypes)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df['date'] = pd.to_datetime(time_df['date'], format='%d-%m-%Y %H:%M') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the transformed data into csv files\n",
    "import os\n",
    "\n",
    "folder='transformed_data'\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "fact_df.to_csv(os.path.join(folder,'t_fact.csv'),index=False)    \n",
    "customer_df.to_csv(os.path.join(folder,'t_customer.csv'),index=False) \n",
    "store_df.to_csv(os.path.join(folder,'t_store.csv'),index=False) \n",
    "item_df.to_csv(os.path.join(folder,'t_item.csv'),index=False) \n",
    "time_df.to_csv(os.path.join(folder,'t_time.csv'),index=False) \n",
    "transaction_df.to_csv(os.path.join(folder,'t_trans.csv'),index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
